# Research Assistant NN Verification

Neural Networks are quite used in many industries. There are many research papers being published for neural networks. However, there can be outcomes from neural networks which leads to different output results as a result of the change in input. Therefore, verification tools are designed and implemented to specify the behavior of the neural network along with verifying it's use. 

I'm currently working under Tan Cheng for Neural Network verification and where I use state-of-the-art tools for building and deploying the neural networks in production. 
My research invovles how changing and altering the neural networks leads to the change in outputs. We test whether a given neural network follows a defined specification. 

<img src = "https://github.com/suhasmaddali/Images/blob/main/Research%20Assistant%20Image.jpg" width = 750/>

One of the interesting applicatios of Neural Network Verification is in self-driving cars. In the case of motion planning and other activities, neural networks are used extensively. Attackers try to modify the outputs from the Neural Networks by applying a distored version of the input. As a result, the output from the Neural Network is different from what is actually expected from the network. This leads to dire consequences such as the model not able to accurately classify whether there are walls present in front of it. This leads to road accidents and leads us to question the safety measures of self-driving cars.
